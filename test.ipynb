{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bf6ea0-d1ad-471e-aa85-f00a752e88f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Jupyter 내부 인자 무시됨: ['-f', 'C:\\\\Users\\\\m\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-5f66ebf9-b0d4-4e4f-8e55-e4167922009a.json']\n",
      "[INFO] Using device: cuda, dtype: torch.bfloat16\n",
      "[INFO] Loading Base Model: LGAI-EXAONE/EXAONE-4.0-1.2B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶▶▶ [Mode] Loading LoRA Adapter from: ./korsmishing-qlora-smishing-expl_확장 ◀◀◀\n",
      "[INFO] Loading CSV from test.csv\n",
      "[INFO] Total samples: 2828\n",
      "[INFO] Running inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e08e10fb664a3d88d5f605e0f2eeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/354 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Evaluation Results ==========\n",
      "Accuracy: 0.9261\n",
      "Macro F1: 0.9217\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         스미싱       0.89      0.99      0.94      1654\n",
      "          정상       0.99      0.83      0.90      1174\n",
      "\n",
      "    accuracy                           0.93      2828\n",
      "   macro avg       0.94      0.91      0.92      2828\n",
      "weighted avg       0.93      0.93      0.92      2828\n",
      "\n",
      "========================================\n",
      "[INFO] Metrics saved to: metrics_result.csv\n",
      "[INFO] Predictions saved to: predictions_result.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =====================================================\n",
    "# 1. 기본 설정\n",
    "# =====================================================\n",
    "BASE_MODEL  = os.getenv(\"BASE_MODEL\", \"LGAI-EXAONE/EXAONE-4.0-1.2B\")\n",
    "ADAPTER_DIR = \"./korsmishing-qlora-smishing-expl_확장\" \n",
    "CACHE_DIR   = r\"C:\\hf_models\\_cache\"\n",
    "HF_TOKEN    = os.getenv(\"HUGGINGFACE_HUB_TOKEN\", \"\").strip() or None\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# 추론 설정 (학습 때와 동일하게 맞춤)\n",
    "GEN_MAX_NEW_TOKENS = 200 \n",
    "GEN_TEMPERATURE    = 0.1 \n",
    "GEN_REP_PENALTY    = 1.1 \n",
    "NO_REPEAT_NGRAM    = 4\n",
    "\n",
    "# =====================================================\n",
    "# 2. 유틸: 프롬프트 및 파싱\n",
    "# =====================================================\n",
    "@contextmanager\n",
    "def left_pad(tok):\n",
    "    old = tok.padding_side\n",
    "    tok.padding_side = \"left\"\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        tok.padding_side = old\n",
    "\n",
    "def build_prompt(text: str) -> str:\n",
    "    # 시스템 메시지\n",
    "    system_msg = \"너는 문자를 분석하여 스미싱 여부를 판단하고, 그 이유를 설명하는 보안 전문가야.\"\n",
    "    \n",
    "    # 유저 메시지 (간결한 답변 유도)\n",
    "    user_msg = (\n",
    "        \"다음 $$문자$$를 보고 먼저 $$스미싱 여부$$를 판단한 뒤, 그 이유를 한두 문장으로 제시하세요.\\n\"\n",
    "        \"형식:\\n\"\n",
    "        \"$$스미싱 여부$$: (스미싱/정상)\\n\"\n",
    "        \"$$설명$$: (간단한 설명)\\n\\n\"\n",
    "        f\"$$문자$$\\n{text}\"\n",
    "        \"<답변>\\n\"\n",
    "    )\n",
    "    \n",
    "    # EXAONE 공식 포맷 조립\n",
    "    return (\n",
    "        f\"[|system|]{system_msg}[|endofturn|]\\n\"\n",
    "        f\"[|user|]{user_msg}[|endofturn|]\\n\"\n",
    "        \"[|assistant|]\"\n",
    "    )\n",
    "\n",
    "def normalize_for_label(text: str) -> str:\n",
    "    return text.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "def parse_label_and_expl(text: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    강건한 파싱 로직 적용:\n",
    "    - 오타(스미링, 스미encing 등) 대응\n",
    "    - 깨진 태그 대응\n",
    "    \"\"\"\n",
    "    # 1. 특수 토큰 제거\n",
    "    text = text.replace(\"[|endofturn|]\", \"\").replace(\"</s>\", \"\").strip()\n",
    "    \n",
    "    label = None\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # [1단계] 강력한 정규식 탐지 (오타 포함 패턴 매칭)\n",
    "    # ------------------------------------------------------------------\n",
    "    # \"$$스미\"로 시작해서 \"여부$$\"로 끝나는 구간 사이에 무엇이 있든 잡아냄\n",
    "    smishing_pattern = r\"\\$\\$스미.{0,10}여부\\$\\$[:：]?\\s*(스미싱|정상)\"\n",
    "    \n",
    "    m = re.search(smishing_pattern, text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        label = m.group(1)\n",
    "        \n",
    "    # [2단계] 태그가 아예 깨졌을 때 (예: 스미싱여부: 정상)\n",
    "    if label is None:\n",
    "        clean_text = text.replace(\" \", \"\")\n",
    "        # 스미싱/스미신/스미링 등 다양한 오타 허용\n",
    "        m2 = re.search(r\"스미[싱신링닝핑a-z]*여부[:：]?\\s*(스미싱|정상)\", clean_text, flags=re.IGNORECASE)\n",
    "        if m2:\n",
    "            label = m2.group(1)\n",
    "\n",
    "    # [3단계] 최후의 수단: 문장 내 키워드 우선순위 확인\n",
    "    if label is None:\n",
    "        head = text[:50] # 앞부분 50자만 확인\n",
    "        has_smishing = \"스미싱\" in head\n",
    "        has_normal = \"정상\" in head\n",
    "        \n",
    "        if has_smishing and not has_normal:\n",
    "            label = \"스미싱\"\n",
    "        elif has_normal and not has_smishing:\n",
    "            label = \"정상\"\n",
    "        elif has_smishing and has_normal:\n",
    "            # 둘 다 있으면 뒤에 나온 걸 선택 (보통 '스미싱 여부: 정상' 형식이므로)\n",
    "            label = \"정상\" if head.rfind(\"정상\") > head.rfind(\"스미싱\") else \"스미싱\"\n",
    "        else:\n",
    "            label = \"판단불가\" # 끝내 못 찾음\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # [설명 파싱] $$설명$$ 뒤에 ``` 같은 거 붙어도 처리\n",
    "    # ------------------------------------------------------------------\n",
    "    exp = text\n",
    "    m_exp = re.search(r\"\\$\\$설명.{0,5}[:：]?\\s*(.+)\", text, flags=re.S)\n",
    "    \n",
    "    if m_exp:\n",
    "        exp = m_exp.group(1).strip()\n",
    "        # 불필요한 기호 제거\n",
    "        exp = re.sub(r\"^[```:：\\s]+\", \"\", exp)\n",
    "    else:\n",
    "        # 태그 없으면 원본 반환 (혹은 추가 정제 가능)\n",
    "        pass\n",
    "\n",
    "    return label, exp\n",
    "\n",
    "# =====================================================\n",
    "# 3. 배치 추론 함수\n",
    "# =====================================================\n",
    "@torch.no_grad()\n",
    "def batch_generate_raw(texts: List[str], model, tokenizer, batch_size: int = 8) -> List[str]:\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating\", unit=\"batch\"):\n",
    "        chunk = texts[i:i + batch_size]\n",
    "        prompts = [build_prompt(t) for t in chunk]\n",
    "        \n",
    "        with left_pad(tokenizer):\n",
    "            enc = tokenizer(\n",
    "                prompts,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=1024, \n",
    "                padding=True,\n",
    "            )\n",
    "        enc.pop(\"token_type_ids\", None)\n",
    "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "\n",
    "        out = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=GEN_MAX_NEW_TOKENS,\n",
    "            do_sample=False,\n",
    "            temperature=GEN_TEMPERATURE,\n",
    "            repetition_penalty=GEN_REP_PENALTY,\n",
    "            no_repeat_ngram_size=NO_REPEAT_NGRAM,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "        in_len = enc[\"input_ids\"].shape[1]\n",
    "        for j in range(out.size(0)):\n",
    "            gen_text = tokenizer.decode(\n",
    "                out[j][in_len:], skip_special_tokens=True\n",
    "            ).strip()\n",
    "            results.append(gen_text)\n",
    "\n",
    "    return results\n",
    "\n",
    "# =====================================================\n",
    "# 4. 평가 실행 및 CSV 저장\n",
    "# =====================================================\n",
    "def evaluate_csv(\n",
    "    csv_path: str,\n",
    "    model, \n",
    "    tokenizer,\n",
    "    text_col: str = \"content\",\n",
    "    label_col: str = \"label\",\n",
    "    batch_size: int = 8,\n",
    "    encoding: str = \"utf-8-sig\",\n",
    "):\n",
    "    print(f\"[INFO] Loading CSV from {csv_path}\")\n",
    "    try:\n",
    "        if encoding:\n",
    "            df = pd.read_csv(csv_path, encoding=encoding)\n",
    "        else:\n",
    "            df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] CSV 로드 실패: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # 컬럼 확인\n",
    "    if text_col not in df.columns or label_col not in df.columns:\n",
    "        print(f\"[Error] CSV에 '{text_col}' 또는 '{label_col}' 컬럼이 없습니다.\")\n",
    "        return None, None\n",
    "\n",
    "    texts   = df[text_col].astype(str).tolist()\n",
    "    y_true  = df[label_col].astype(str).tolist()\n",
    "\n",
    "    print(f\"[INFO] Total samples: {len(df)}\")\n",
    "    print(\"[INFO] Running inference...\")\n",
    "    \n",
    "    # 1. 추론\n",
    "    raw_outputs = batch_generate_raw(texts, model, tokenizer, batch_size=batch_size)\n",
    "    \n",
    "    # 2. 파싱\n",
    "    parsed = [parse_label_and_expl(o) for o in raw_outputs]\n",
    "    y_pred, exp_pred = zip(*parsed)\n",
    "\n",
    "    # 3. 지표 계산\n",
    "    labels = [\"스미싱\", \"정상\"]\n",
    "    \n",
    "    # 라벨에 없는 값('판단불가' 등)은 통계에서 경고를 띄우지 않기 위해 처리 필요할 수 있음\n",
    "    # 여기서는 sklearn이 알아서 처리하도록 둠 (Warning 뜰 수 있음)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=labels, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    macro_f1 = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)[2]\n",
    "\n",
    "    print(\"\\n========== Evaluation Results ==========\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, labels=labels, zero_division=0))\n",
    "    print(\"========================================\")\n",
    "\n",
    "    # 4. 데이터 저장 준비\n",
    "    metrics = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Macro_F1\": macro_f1,\n",
    "        \"F1_Smishing\": f1[0] if len(f1) > 0 else 0,\n",
    "        \"F1_Normal\": f1[1] if len(f1) > 1 else 0,\n",
    "        \"Precision_Smishing\": precision[0] if len(precision) > 0 else 0,\n",
    "        \"Recall_Smishing\": recall[0] if len(recall) > 0 else 0,\n",
    "    }\n",
    "\n",
    "    df_preds = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"label_true\": y_true,\n",
    "        \"label_pred\": list(y_pred),\n",
    "        \"explanation_pred\": list(exp_pred),\n",
    "        \"raw_output\": raw_outputs,\n",
    "    })\n",
    "\n",
    "    return metrics, df_preds\n",
    "\n",
    "# =====================================================\n",
    "# 5. 메인 함수 (Jupyter 에러 수정 버전)\n",
    "# =====================================================\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # --csv_path 기본값 설정\n",
    "    parser.add_argument(\"--csv_path\",       type=str, default=\"test.csv\", help=\"Path to test CSV file\")\n",
    "    parser.add_argument(\"--text_col\",       type=str, default=\"content\")\n",
    "    parser.add_argument(\"--label_col\",      type=str, default=\"label\")\n",
    "    parser.add_argument(\"--batch_size\",     type=int, default=8)\n",
    "    parser.add_argument(\"--encoding\",       type=str, default=\"utf-8-sig\")\n",
    "    parser.add_argument(\"--metrics_out\",    type=str, default=\"metrics_result.csv\")\n",
    "    parser.add_argument(\"--preds_out\",      type=str, default=\"predictions_result.csv\")\n",
    "    \n",
    "    # 어댑터 사용 여부 스위치\n",
    "    parser.add_argument(\"--no_adapter\",     action=\"store_true\", help=\"Use base model without LoRA adapter\")\n",
    "\n",
    "    # ★★★ [핵심 수정] parse_args() -> parse_known_args()로 변경 ★★★\n",
    "    # 이렇게 하면 주피터가 넘기는 -f 인자를 'unknown' 변수로 받아내고 에러를 내지 않습니다.\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if unknown:\n",
    "        print(f\"[INFO] Jupyter 내부 인자 무시됨: {unknown}\")\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.bfloat16 if (device==\"cuda\" and torch.cuda.get_device_capability(0)[0] >= 8) else torch.float32\n",
    "    print(f\"[INFO] Using device: {device}, dtype: {dtype}\")\n",
    "\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        BASE_MODEL, cache_dir=CACHE_DIR, token=HF_TOKEN, use_fast=True\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    # 모델 로드\n",
    "    print(f\"[INFO] Loading Base Model: {BASE_MODEL}\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        cache_dir=CACHE_DIR,\n",
    "        token=HF_TOKEN,\n",
    "        device_map=\"auto\" if device == \"cuda\" else None,\n",
    "        torch_dtype=dtype,\n",
    "    )\n",
    "\n",
    "    # 스위치: LoRA 쓸지 말지 결정\n",
    "    if args.no_adapter:\n",
    "        print(\"▶▶▶ [Mode] Running with BASE MODEL ONLY (No Adapter) ◀◀◀\")\n",
    "        model = base_model\n",
    "    else:\n",
    "        print(f\"▶▶▶ [Mode] Loading LoRA Adapter from: {ADAPTER_DIR} ◀◀◀\")\n",
    "        try:\n",
    "            model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] 어댑터 로드 실패: {e}\")\n",
    "            print(\"어댑터 경로가 정확한지, 학습이 제대로 끝났는지 확인해주세요.\")\n",
    "            return\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # 평가 수행\n",
    "    metrics, df_preds = evaluate_csv(\n",
    "        csv_path=args.csv_path,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        text_col=args.text_col,\n",
    "        label_col=args.label_col,\n",
    "        batch_size=args.batch_size,\n",
    "        encoding=args.encoding,\n",
    "    )\n",
    "\n",
    "    if metrics is not None:\n",
    "        # 결과 저장\n",
    "        pd.DataFrame([metrics]).to_csv(args.metrics_out, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"[INFO] Metrics saved to: {args.metrics_out}\")\n",
    "        \n",
    "        df_preds.to_csv(args.preds_out, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"[INFO] Predictions saved to: {args.preds_out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f89205-1e54-4e84-ac92-b321461962f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (torch)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
